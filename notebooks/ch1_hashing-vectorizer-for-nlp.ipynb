{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"FIrst lets import the textual dataset. Our Aim is to convert it into numerical form , amenable to machine learning algorithms","metadata":{}},{"cell_type":"code","source":"with open(\"../input/irc-channel-logs/anonops_short.txt\", encoding=\"utf8\") as f:\n    anonops_chat_logs = f.readlines()","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Lets count the words in text using hash vectorizer and then perform weighting using tf-idf","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import HashingVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"my_vector = HashingVectorizer(input=\"content\", ngram_range=(1,2))\nX_train_counts = my_vector.fit_transform(anonops_chat_logs)\ntf_transformer = TfidfTransformer(use_idf = True).fit(X_train_counts)\nX_train_tf = tf_transformer.transform(X_train_counts)","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"End result is sparse matrix with each row being a vector representing one of the texts","metadata":{}},{"cell_type":"code","source":"X_train_tf","metadata":{"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<180830x1048576 sparse matrix of type '<class 'numpy.float64'>'\n\twith 3158166 stored elements in Compressed Sparse Row format>"},"metadata":{}}]},{"cell_type":"code","source":"print(X_train_tf)","metadata":{"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"  (0, 938273)\t0.10023429482560929\n  (0, 871172)\t-0.33044470291777067\n  (0, 755834)\t-0.2806123960092745\n  (0, 556974)\t-0.2171490773135763\n  (0, 548264)\t-0.09851435603064428\n  (0, 531189)\t-0.2566310842337745\n  (0, 522961)\t-0.3119912982467716\n  (0, 514190)\t-0.2527659565181208\n  (0, 501800)\t-0.33044470291777067\n  (0, 499727)\t-0.18952297847436425\n  (0, 488876)\t0.13502094828386488\n  (0, 377854)\t0.22710724511856722\n  (0, 334594)\t-0.25581186158424035\n  (0, 256577)\t0.20949022238574433\n  (0, 197273)\t-0.30119674850360456\n  (0, 114899)\t0.09713499033205285\n  (0, 28523)\t-0.3060506288368513\n  (1, 960098)\t0.09780838928665199\n  (1, 955748)\t-0.2747271490090429\n  (1, 952302)\t0.26070217969901804\n  (1, 938273)\t0.12095603891963835\n  (1, 937092)\t-0.2947114257264502\n  (1, 927866)\t0.21727726371674563\n  (1, 820768)\t-0.11065660403137358\n  (1, 772066)\t-0.14344517367198276\n  :\t:\n  (180828, 329790)\t0.06808618130417012\n  (180828, 312887)\t-0.08249409552977467\n  (180828, 209871)\t0.17685927011939476\n  (180828, 193711)\t-0.14127016157231428\n  (180828, 181881)\t-0.11885031537539834\n  (180828, 180525)\t-0.06925490785130799\n  (180828, 156500)\t-0.20787461071537122\n  (180828, 148568)\t0.1963433059906426\n  (180828, 82508)\t-0.1289257787752738\n  (180828, 79994)\t0.23121076025389292\n  (180828, 78098)\t-0.18205107240120946\n  (180828, 47738)\t0.23121076025389292\n  (180828, 46353)\t0.1045181919567425\n  (180828, 45900)\t-0.09537730182105167\n  (180828, 45419)\t-0.11189579574426382\n  (180828, 11712)\t-0.16947494737589616\n  (180829, 1026910)\t0.4082112914772047\n  (180829, 975831)\t-0.18401193506169794\n  (180829, 936283)\t0.2472007199039777\n  (180829, 856299)\t-0.15436175878438183\n  (180829, 473183)\t-0.41092004816695277\n  (180829, 464504)\t0.2928849862993687\n  (180829, 251872)\t-0.4714000763194845\n  (180829, 189128)\t0.44418614795477124\n  (180829, 45900)\t-0.20102520636796686\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We started by loading in the #Anonops text dataset (step 1). The Anonops IRC channel has\nbeen affiliated with the Anonymous hacktivist group. In particular, chat participants have\nin the past planned and announced their future targets on Anonops. Consequently, a well\u0002engineered ML system would be able to predict cyber attacks by training on such data. In\nstep 2, we instantiated a hashing vectorizer. The hashing vectorizer gave us counts of the 1-\nand 2-grams in the text, in other words, singleton and consecutive pairs of words (tokens)\nin the articles. We then applied a tf-idf transformer to give appropriate weights to the\ncounts that the hashing vectorizer gave us. Our final result is a large, sparse matrix\nrepresenting the occurrences of 1- and 2-grams in the texts, weighted by importance.\nFinally, we examined the frontend of a sparse matrix representation of our featured data in\nScipy.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}