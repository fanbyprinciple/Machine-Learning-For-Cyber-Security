{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This taken from chapter 3 of the book [Machine learning for cybersecurity cookbook](https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter03/)\n\nUsing Generative Adversarial Networks (GANs), we can create adversarial malware\nsamples to train and improve our detection methodology, as well as to identify gaps before\nan adversary does. The code here is based on j40903272/MalConv-keras. The adversarial \nmalware samples are malware samples that have been modified by padding them with a\nsmall, but carefully calculated, sequence of bytes, selected so as to fool the neural network\n(in this case, MalConv) being used to classify the samples.","metadata":{}},{"cell_type":"markdown","source":"Getting the input from their github repository.","metadata":{}},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/master/Chapter03/MalGan/MalGAN_input/samplesIn.csv","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"--2021-05-09 06:04:29--  https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/master/Chapter03/MalGan/MalGAN_input/samplesIn.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1700 (1.7K) [text/plain]\nSaving to: ‘samplesIn.csv.1’\n\nsamplesIn.csv.1     100%[===================>]   1.66K  --.-KB/s    in 0s      \n\n2021-05-09 06:04:29 (23.6 MB/s) - ‘samplesIn.csv.1’ saved [1700/1700]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ndata = pd.read_csv('samplesIn.csv')","metadata":{"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"  0778a070b283d5f4057aeb3b42d58b82ed20e4eb_f205bd9628ff8dd7d99771f13422a665a70bb916  \\\n0  fbd1a4b23eff620c1a36f7c9d48590d2fccda4c2_cc822...                                  \n1  c095da034535f15a27c073dce54212a28e1af683_8e864...                                  \n2  488e5eea345e24440f7d0d2a32fbafda314ee6ca_df473...                                  \n3  7a359bcc1c7ac5f18eff7c3459dadefa9f9e4610_3b7ac...                                  \n4  509038aad80431b8aa0c9b29bfce07fe7134fc7a_263fb...                                  \n\n    0  \n0   0  \n1   0  \n2   0  \n3   0  \n4   0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0778a070b283d5f4057aeb3b42d58b82ed20e4eb_f205bd9628ff8dd7d99771f13422a665a70bb916</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fbd1a4b23eff620c1a36f7c9d48590d2fccda4c2_cc822...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>c095da034535f15a27c073dce54212a28e1af683_8e864...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>488e5eea345e24440f7d0d2a32fbafda314ee6ca_df473...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7a359bcc1c7ac5f18eff7c3459dadefa9f9e4610_3b7ac...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>509038aad80431b8aa0c9b29bfce07fe7134fc7a_263fb...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Lets start by importing code for MalGAN ","metadata":{}},{"cell_type":"markdown","source":"### MalGAN_preprocess.py","metadata":{}},{"cell_type":"code","source":"import os\nimport time\nimport pickle\nimport argparse\nimport pandas as pd\nfrom keras.preprocessing.sequence import pad_sequences","metadata":{"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"parser = argparse.ArgumentParser(description='Malconv-keras classifier')\nparser.add_argument('--max_len', type=int, default=200000)\nparser.add_argument('--save_path', type=str, default='../saved/preprocess_data.pkl')\nparser.add_argument('csv', type=str)","metadata":{"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"_StoreAction(option_strings=[], dest='csv', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help=None, metavar=None)"},"metadata":{}}]},{"cell_type":"code","source":"def preprocess(fn_list, max_len):\n    corpus = []\n    for fn in fn_list:\n        if not os.path.isfile(fn):\n            print(fn, 'not exist')\n        else:\n            with open(fn, 'rb') as f:\n                corpus.append(f.read())\n    \n    corpus = [[byte for byte in doc] for doc in corpus]\n    len_list = [len(doc) for doc in corpus]\n    seq = pad_sequences(corpus, maxlen=max_len, padding='post', truncating='post')\n    return seq, len_list","metadata":{"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def call_preprocess(name, maxlen=200000, savepath='../saved/preprocess_data.pkl' ):\n    df = pd.read_csv(name, header=None)\n    fn_list = df[0].values\n    \n    print('preprocessing... we might be a while here')\n    st = time.time()\n    processed_data = preprocess(fn_list, maxlen)[0]\n    print('Finished ... %d sec' % int(time.time()-st))\n    \n    with open(savepath, 'wb') as f:\n        pickle.dump(preprocessed_data, f)\n    print('Preprocessed data store in ', )","metadata":{"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### MalGAN_utils.py","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\nprint(tf.__version__)","metadata":{"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"2.4.1\n","output_type":"stream"}]},{"cell_type":"code","source":"def fgsm(model, inp, pad_idx, pad_len, e, step_size=0.001):\n    adv = inp.copy()\n    loss = K.mean(model.output[:,0])\n    grads = K.gradients(loss, model.layers[1].output)[0]\n    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-8)\n    \n    mask = np.zeros(model.layers[1].output.shape[1:])\n    mask[pad_idx:pad_idx + pad_len] = 1\n    grads *= K.constant(mask)\n    \n    iterate = K.function([model.layers[1].output], [loss, grads])\n    g = 0.\n    step = int(1/step_size) * 10\n    for _ in range(step):\n        loss_value, grads_value = iterate([adv])\n        grads_value *= step_size\n        g += grads_value\n        adv += grads_value\n        \n        if loss_vale >= 0.9:\n            break\n    return adv, h, loss_value","metadata":{"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def limit_gpu_memory(per):\n    config = tf.ConfigProto()\n    config.gpu_options.per_process_gpu_memory_fraction = per\n    set_session(tf.Session(config=config))","metadata":{"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def train_test_split(data, label, val_size=0.1):\n    idx = np.arange(len(data))\n    np.random.shuffle(idx)\n    split = int(len(data)*val_size)\n    x_train, x_test = data[idx[split:]], data[idx[:split]]\n    y_train, y_test = label[idx[split:]], label[idx[:split]]\n    return x_train, x_test, y_train, y_test","metadata":{"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def data_generator(data, labels, max_len=200000, batch_size=64, shuffle=True):\n    idx = np.arange(len(data))\n    if shuffle:\n        np.random.shuffle(idx)\n    batches = [idx[range(batch_size*i, min(len(data), batch_size*(i+1)))] for i in range(len(data)//batch_size+1)]\n    while True:\n        for i in batches:\n            xx = preprocess(data[i], max_len)[0]\n            yy = labels[i]\n            yield (xx, yy)","metadata":{"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"class logger():\n    def __init__(self):\n        self.fn = []\n        self.len = []\n        self.pad_len = []\n        self.loss = []\n        self.pred = []\n        self.org = []\n    def write(self, fn, org_score, file_len, pad_len, loss, pred):\n        self.fn.append(fn.split('/')[-1])\n        self.org.append(org_score)\n        self.len.append(file_len)\n        self.pad_len.append(pad_len)\n        self.loss.append(loss)\n        self.pred.append(pred)\n        \n        print('\\nFILE:', fn)\n        if pad_len > 0:\n            print('\\tfile length:', file_len)\n            print('\\tpad length:', pad_len)\n            #if not np.isnan(loss):\n            print('\\tloss:', loss)\n            print('\\tscore:', pred)\n        else:\n            print('\\tfile length:', file_len, ', Exceed max length ! Ignored !')\n        print('\\toriginal score:', org_score)\n        \n    def save(self, path):\n        d = {'filename':self.fn, \n             'original score':self.org, \n             'file length':self.len,\n             'pad length':self.pad_len, \n             'loss':self.loss, \n             'predict score':self.pred}\n        df = pd.DataFrame(data=d)\n        df.to_csv(path, index=False, columns=['filename', 'original score', \n                                              'file length', 'pad length', \n                                              'loss', 'predict score'])\n        print('\\nLog saved to \"%s\"\\n' % path)","metadata":{"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"### MalGAN_gen_adv_examples.py","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import NearestNeighbors\nfrom keras import backend as K\nimport numpy as np","metadata":{"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def gen_adv_samples(model, fn_list, pad_percent=0.1, step_size=0.001, thres=0.5):\n    def emb_search(org, adv, pad_idx, pad_len, neigh):\n        out = org.copy()\n        for idx in range(pad_idx, pad_idx + pad_len):\n            target = adv[idx].reshape(1,-1)\n            best_idx = neigh.kneighbors(target, 1, False)[0][0]\n            out[0][idx] = best_idx\n        return out\n    \n    max_len = int(model.input.shape[1])\n    emb_layer = model.layers[1]\n    emb_weight = emb_layer.get_weights()[0]\n    inp2emb = K.function([model.input]+ [K.learning_phase()], [emb_layer.output]) # [function] Map sequence to embedding\n\n    # Build neighbor searches\n    neigh = NearestNeighbors(1)\n    neigh.fit(emb_weight)\n\n    log = logger()\n    adv_samples = []\n    \n    for e, fn in enumerate(fn_list):\n\n        ###   run one file at a time due to different padding length, [slow]\n        inp, len_list = call_preprocess([fn], max_len)\n        inp_emb = np.squeeze(np.array(inp2emb([inp, False])), 0)\n\n        pad_idx = len_list[0]\n        pad_len = max(min(int(len_list[0]*pad_percent), max_len-pad_idx), 0)\n        org_score = model.predict(inp)[0][0]    ### origianl score, 0 -> malicious, 1 -> benign\n        loss, pred = float('nan'), float('nan')\n\n        if pad_len > 0:\n\n            if org_score < thres:\n                adv_emb, gradient, loss = fgsm(model, inp_emb, pad_idx, pad_len, e, step_size)\n                adv = emb_search(inp, adv_emb[0], pad_idx, pad_len, neigh)\n                pred = model.predict(adv)[0][0]\n                final_adv = adv[0][:pad_idx+pad_len]\n\n            else: # use origin file\n                final_adv = inp[0][:pad_idx]\n\n\n        log.write(fn, org_score, pad_idx, pad_len, loss, pred)\n\n        # sequence to bytes\n        bin_adv = bytes(list(final_adv))\n        adv_samples.append(bin_adv)\n\n    return adv_samples, log\n    \n    \n    ","metadata":{"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"### creating GANs","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom keras.models import load_model\n","metadata":{"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"Specifying the input and output path","metadata":{}},{"cell_type":"code","source":"!wget https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/raw/master/Chapter03/MalGan/MalGAN_input/malconv.h5","metadata":{"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"--2021-05-09 06:04:30--  https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/raw/master/Chapter03/MalGan/MalGAN_input/malconv.h5\nResolving github.com (github.com)... 140.82.113.3\nConnecting to github.com (github.com)|140.82.113.3|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/master/Chapter03/MalGan/MalGAN_input/malconv.h5 [following]\n--2021-05-09 06:04:31--  https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/master/Chapter03/MalGan/MalGAN_input/malconv.h5\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 12459832 (12M) [application/octet-stream]\nSaving to: ‘malconv.h5.1’\n\nmalconv.h5.1        100%[===================>]  11.88M  43.4MB/s    in 0.3s    \n\n2021-05-09 06:04:32 (43.4 MB/s) - ‘malconv.h5.1’ saved [12459832/12459832]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"save_path = \"MalGAN_output\"\nmodel_path = \"malconv.h5\"\nlog_path = \"MalGAN_output/adversarial_log.csv\"\npad_percent = 0.1\nthreshold = 0.6\nstep_size = 0.01\nlimit = 0.\ninput_samples = \"samplesIn.csv\"\n\ndf = pd.read_csv(input_samples, header=None)\nfn_list = df[0].values\nmodel = load_model(model_path)\n\n# print(gen_adv_samples(model, fn_list, pad_percent,step_size, threshold))\n# adv_samples, log= gen_adv_samples(model, fn_list, pad_percent,step_size, threshold)\n\n# log.save(log_path)\n\n# for fn, adv in zip(fn_list, adv_samples):\n#     _fn = fn.split()\n#     dst = os.path.join(save_path, _fn)\n#     print(dst)\n#     with open(dst, 'wb') as f:\n#         f.write(adv)","metadata":{"trusted":true},"execution_count":49,"outputs":[]}]}