{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook is adapted from code given in `https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook`","metadata":{}},{"cell_type":"markdown","source":"# PART 1 Getting the data","metadata":{}},{"cell_type":"code","source":"!wget https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/raw/master/Chapter03/Resources/DA%20Logs%20Benign%201.7z\n!wget https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/raw/master/Chapter03/Resources/DA%20Logs%20Benign%202.7z\n!wget https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/raw/master/Chapter03/Resources/DA%20Logs%20Benign%203.7z\n    \n!wget https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/raw/master/Chapter03/Resources/DA%20Logs%20Malware%201.7z\n!wget https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/raw/master/Chapter03/Resources/DA%20Logs%20Malware%202.7z\n!wget https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/raw/master/Chapter03/Resources/DA%20Logs%20Malware%203.7z\n!wget https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/raw/master/Chapter03/Resources/DA%20Logs%20Malware%204.7z\n!wget https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/raw/master/Chapter03/Resources/DA%20Logs%20Malware%205.7z\n!wget https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/raw/master/Chapter03/Resources/DA%20Logs%20Malware%206.7z","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!dir","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt install p7zip-full p7zip-rar -y ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir DA_logs_Benign\n!mkdir DA_logs_Malware","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd DA_logs_Benign/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(1,4):\n  !7z e -y ../DA\\ Logs\\ Benign\\ {i}.7z ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd ../DA_logs_Malware/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"for i in range(1,7):\n  !7z e -y ../DA\\ Logs\\ Malware\\ {i}.7z -pinfected","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd ..","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# will deal with the empty directories later\n\n# for i in range(1,3):\n#     !rm -rf \"/content/Malicious_PE_samples/Malicious PE Samples {i}\"\n\n# for i in range(1,7):\n#      !rm -rf \"/content/Benign_PE_samples/Benign PE Samples {i}\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PART 2 creating a malware detection model based on API calls","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport json\n\ndirectories_with_labels = [(\"DA_logs_Benign\",0),(\"DA_logs_Malware\", 1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_API_class_method_type_from_log(log):\n    \"\"\"Parses out API calls from behavioral logs.\"\"\"\n    API_data_sequence = []\n    with open(log) as log_file:\n        json_log = json.load(log_file)\n        api_calls_array = \"[\" + json_log[\"api_calls\"] + \"]\"\n        api_calls = json.loads(api_calls_array)\n        for api_call in api_calls:\n            data = api_call[\"class\"] + \":\" + api_call[\"method\"] + \":\" + api_call[\"type\"]\n            API_data_sequence.append(data)\n    return API_data_sequence\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_corpus = []\nlabels = []\n\nfor directory, label in directories_with_labels:\n    logs = os.listdir(directory)\n    for log_path in logs:\n        file_path = directory + \"/\" + log_path\n        try:\n            data_corpus.append(get_API_class_method_type_from_log(file_path))\n            labels.append(label)\n        except:\n            pass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we do a train test split","metadata":{}},{"cell_type":"code","source":"print(data_corpus[0][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we use N grams so we loadour Ngram extraction function, with a slight modification for the current data format","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ncorpus_train, corpus_test, y_train, y_test = train_test_split(data_corpus, labels, test_size=0.2, random_state=11)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our approach is to use N grams so we load our Ngram extraction functions with a slight modificaiton for the current dat format","metadata":{}},{"cell_type":"code","source":"\nimport collections\nfrom nltk import ngrams\nimport numpy as np\n\n\ndef read_file(file_path):\n    \"\"\"Reads in the binary sequence of a binary file.\"\"\"\n    with open(file_path, \"rb\") as binary_file:\n        data = binary_file.read()\n    return data\n\n\ndef text_to_Ngrams(text, n):\n    \"\"\"Produces a list of N-grams from a text.\"\"\"\n    Ngrams = ngrams(text, n)\n    return list(Ngrams)\n\n\ndef get_Ngram_counts(text, N):\n    \"\"\"Get a frequency count of N-grams in a text.\"\"\"\n    Ngrams = text_to_Ngrams(text, N)\n    return collections.Counter(Ngrams)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N = 4\ntotal_Ngram_count = collections.Counter([])\nfor file in corpus_train:\n    total_Ngram_count += get_Ngram_counts(file, N)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(total_Ngram_count)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"K1 = 3000\nK1_most_frequent_Ngrams = total_Ngram_count.most_common(K1)\nK1_most_frequent_Ngrams_list = [x[0] for x in K1_most_frequent_Ngrams]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"K1_most_frequent_Ngrams_list[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def featurize_sample(file, Ngrams_list):\n    K1 = len(Ngrams_list)\n    feature_vector = K1 * [0]\n    fileNgrams = get_Ngram_counts(file, N)\n    for i in range(K1):\n        feature_vector[i] = fileNgrams[Ngrams_list[i]]\n    return feature_vector","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = []\ntry:\n    for sample in corpus_train:\n        X_train.append(featurize_sample(sample, K1_most_frequent_Ngrams_list))\nexcept Exception as e:\n    print(e)\n    \nX_train = np.asarray(X_train)\nX_test = []\n\nfor sample in corpus_test:\n    X_test.append(featurize_sample(sample, K1_most_frequent_Ngrams_list))\nX_test = np.asarray(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest, muttual_info_classif\nfrom sklearn.pipeline import Pipeline\nfrom xgboost import XGBClasssifier\n\nK2 = 500\nmi_pipeline = Pipeline(\n    [\n        (\"mutual_information\", SelectKBest(mutual_info_classif, k=K2)),\n        (\"xgb\", XGBClassifier())\n    ]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mi_pipeline.fit(X_train, y_train)\nprint(\"accuracy training and testing : \")\nprint(mi_pipeline.score(X_train, y_train))\nprint(mi_pipeline.score(X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}