{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This is taken from lesson 2 in https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/blob/master/Chapter02/","metadata":{}},{"cell_type":"code","source":"! wget \"https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/raw/master/Chapter02/Resources/test_data.npz\"\n! wget \"https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/raw/master/Chapter02/Resources/training_data.npz\"\n! wget \"https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/raw/master/Chapter02/Resources/test_labels.npy\"\n! wget \"https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/raw/master/Chapter02/Resources/training_labels.npy\"","metadata":{"id":"k15czt_lZ7Jw","outputId":"475201aa-be00-4fe1-8d4a-0a0c8c0cf3e5","trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"--2021-05-02 05:34:19--  https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/raw/master/Chapter02/Resources/test_data.npz\nResolving github.com (github.com)... 140.82.113.4\nConnecting to github.com (github.com)|140.82.113.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/master/Chapter02/Resources/test_data.npz [following]\n--2021-05-02 05:34:20--  https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/master/Chapter02/Resources/test_data.npz\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 38887 (38K) [application/octet-stream]\nSaving to: ‘test_data.npz’\n\ntest_data.npz       100%[===================>]  37.98K  --.-KB/s    in 0.002s  \n\n2021-05-02 05:34:20 (19.8 MB/s) - ‘test_data.npz’ saved [38887/38887]\n\n--2021-05-02 05:34:21--  https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/raw/master/Chapter02/Resources/training_data.npz\nResolving github.com (github.com)... 140.82.113.4\nConnecting to github.com (github.com)|140.82.113.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/master/Chapter02/Resources/training_data.npz [following]\n--2021-05-02 05:34:21--  https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/master/Chapter02/Resources/training_data.npz\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 71999 (70K) [application/octet-stream]\nSaving to: ‘training_data.npz’\n\ntraining_data.npz   100%[===================>]  70.31K  --.-KB/s    in 0.008s  \n\n2021-05-02 05:34:22 (8.96 MB/s) - ‘training_data.npz’ saved [71999/71999]\n\n--2021-05-02 05:34:22--  https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/raw/master/Chapter02/Resources/test_labels.npy\nResolving github.com (github.com)... 140.82.113.4\nConnecting to github.com (github.com)|140.82.113.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/master/Chapter02/Resources/test_labels.npy [following]\n--2021-05-02 05:34:23--  https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/master/Chapter02/Resources/test_labels.npy\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 652 [application/octet-stream]\nSaving to: ‘test_labels.npy’\n\ntest_labels.npy     100%[===================>]     652  --.-KB/s    in 0s      \n\n2021-05-02 05:34:23 (20.6 MB/s) - ‘test_labels.npy’ saved [652/652]\n\n--2021-05-02 05:34:24--  https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/raw/master/Chapter02/Resources/training_labels.npy\nResolving github.com (github.com)... 140.82.113.4\nConnecting to github.com (github.com)|140.82.113.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/master/Chapter02/Resources/training_labels.npy [following]\n--2021-05-02 05:34:24--  https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/master/Chapter02/Resources/training_labels.npy\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1120 (1.1K) [application/octet-stream]\nSaving to: ‘training_labels.npy’\n\ntraining_labels.npy 100%[===================>]   1.09K  --.-KB/s    in 0s      \n\n2021-05-02 05:34:24 (40.6 MB/s) - ‘training_labels.npy’ saved [1120/1120]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install sklearn imbalanced-learn","metadata":{"id":"WI3VK_g7aeTZ","outputId":"da8f1b91-39d2-4aa6-8098-b28cc9bf471e","trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (0.0)\nRequirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.7/site-packages (0.8.0)\nRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (1.5.4)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (1.0.1)\nRequirement already satisfied: scikit-learn>=0.24 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (0.24.1)\nRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (1.19.5)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.24->imbalanced-learn) (2.1.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn import tree\nfrom sklearn.metrics import balanced_accuracy_score\nimport numpy as np\nimport scipy.sparse \nimport collections","metadata":{"id":"0XGMyw0Bang1","trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"X_train = scipy.sparse.load_npz(\"training_data.npz\")\ny_train = np.load(\"training_labels.npy\")\nX_test = scipy.sparse.load_npz(\"test_data.npz\")\ny_test = np.load(\"test_labels.npy\")","metadata":{"id":"oaS1gi0uaz6r","trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"X_train, y_train, X_test, y_test","metadata":{"id":"Z422KZmZjrxF","outputId":"7a21e5ca-b920-4dc1-d22c-4585c868b340","trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(<248x2097153 sparse matrix of type '<class 'numpy.float64'>'\n \twith 13990 stored elements in COOrdinate format>,\n array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n        1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n        0, 1, 0, 0, 0, 1], dtype=int32),\n <131x2097153 sparse matrix of type '<class 'numpy.float64'>'\n \twith 7184 stored elements in COOrdinate format>,\n array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n       dtype=int32))"},"metadata":{}}]},{"cell_type":"code","source":"dt = tree.DecisionTreeClassifier()\ndt.fit(X_train, y_train)\ndt_pred = dt.predict(X_test)\nprint(collections.Counter(dt_pred))\nprint(balanced_accuracy_score(y_test, dt_pred))","metadata":{"id":"8cPjFzKdbH0F","outputId":"87ef9e09-97e9-456c-fc15-6533cea83e76","trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Counter({0: 120, 1: 11})\n0.8290229885057472\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## we can try several ways to improve the performace","metadata":{"id":"14CqntnGcF-o"}},{"cell_type":"markdown","source":"### Weighting ","metadata":{"id":"KqA6VIfbcQ0x"}},{"cell_type":"code","source":"dt_weighted = tree.DecisionTreeClassifier(class_weight=\"balanced\")\ndt_weighted.fit(X_train, y_train)\ndt_weighted_pred = dt_weighted.predict(X_test)\nprint(collections.Counter(dt_weighted_pred))\nprint(balanced_accuracy_score(y_test, dt_weighted_pred))","metadata":{"id":"4_AxMzDPbZSe","outputId":"427b142b-d9bc-4f7b-9121-fbcab2e67049","trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Counter({0: 114, 1: 17})\n0.9913793103448276\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Upsampling the minorclass","metadata":{"id":"ZFhujOCkcVJk"}},{"cell_type":"code","source":"from sklearn.utils import resample","metadata":{"id":"UDNdU6j0cLg1","trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X_train_np = X_train.toarray()\nclass_0_indices = [i for i, x in enumerate(y_train == 0) if x]\nclass_1_indices = [i for i, x in enumerate(y_train == 1) if x]\nsize_class_0 = sum(y_train == 0)\n\n\nx_train_class_0 = X_train_np[class_0_indices, :]\ny_train_class_0 = [0] * size_class_0\nx_train_class_1 = X_train_np[class_1_indices, :]\ny_train_class_1 = [1] * (len(y_train) - size_class_0)","metadata":{"id":"3Zps15PIcMd0","trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# We upsample the elements of class 1 with replacements until the number ofsamples of class 1 and class 0 are equal\nX_train_class_1_resampled = resample(x_train_class_1, replace=True, n_samples=size_class_0)\ny_train_class_1_resampled = [1] * size_class_0","metadata":{"id":"-GmHV5wUeF8q","trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# combining\nX_train_resampled = np.concatenate([x_train_class_0, X_train_class_1_resampled])\ny_train_resampled = y_train_class_0 + y_train_class_1_resampled","metadata":{"id":"SXQYy3wBfGf4","trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# training a random forest\nfrom scipy import sparse\n\nX_train_resampled = sparse.csr_matrix(X_train_resampled)\ndt_resampled = tree.DecisionTreeClassifier()\ndt_resampled.fit(X_train_resampled, y_train_resampled)\ndt_resampled_pred = dt_resampled.predict(X_test)\nprint(collections.Counter(dt_resampled_pred))\nprint(balanced_accuracy_score(y_test, dt_resampled_pred))\n","metadata":{"id":"MBc-sFWtcM-X","trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Counter({0: 114, 1: 17})\n0.9913793103448276\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Downsampling the major class","metadata":{"id":"Jo-nRE5ufyT0"}},{"cell_type":"code","source":"X_train_np = X_train.toarray()\nclass_0_indices = [i for i, x in enumerate(y_train==0) if x]\nclass_1_indices = [i for i, x in enumerate(y_train == 1) if x]\nsize_class_1 = sum(y_train == 1)\nX_train_class_1 = X_train_np[class_1_indices, :]\ny_train_class_1 = [1] * size_class_1\nX_train_class_0 = X_train_np[class_0_indices, :]\nX_train_class_0_downsampled = resample(\n    X_train_class_0, replace=False, n_samples=size_class_1\n)\ny_train_class_0_downsampled = [0] * size_class_1","metadata":{"id":"muczzkwggcHN","trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"X_train_downsampled = np.concatenate([X_train_class_1, X_train_class_0_downsampled])\ny_train_downsampled = y_train_class_1 + y_train_class_0_downsampled","metadata":{"id":"3pVyMFPehP4n","trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"X_train_downsampled = sparse.csr_matrix(X_train_downsampled)\ndt_downsampled = tree.DecisionTreeClassifier()\ndt_downsampled.fit(X_train_downsampled, y_train_downsampled)\ndt_downsampled_pred = dt_downsampled.predict(X_test)\nprint(collections.Counter(dt_downsampled_pred))\nprint(balanced_accuracy_score(y_test, dt_downsampled_pred))","metadata":{"id":"vqs3MhBHher-","trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Counter({0: 114, 1: 17})\n0.9913793103448276\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### classifier including inner balancing samplers","metadata":{"id":"vWxpMixIiB0A"}},{"cell_type":"code","source":"from imblearn.ensemble import BalancedBaggingClassifier\n\nbalanced_clf = BalancedBaggingClassifier(\n    base_estimator = tree.DecisionTreeClassifier(),\n    sampling_strategy = \"auto\",\n    replacement = True\n)\n\nbalanced_clf.fit (X_train, y_train)\nbalanced_clf_pred = balanced_clf.predict(X_test)\nprint(collections.Counter(balanced_clf_pred))\nprint(balanced_accuracy_score(y_test, balanced_clf_pred))","metadata":{"id":"_odLMGIah_W8","trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Counter({0: 113, 1: 18})\n0.9870689655172413\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We start by loading in a predefined dataset (step 1) using the scipy.sparse.load_npz\nloading function to load previously saved sparse matrices. Our next step is to train a basic\nDecision Tree model on our data (step 2). To measure performance, we utilize the balanced\naccuracy score, a measure that is often used in classification problems with imbalanced\ndatasets. By definition, balanced accuracy is the average of recall obtained on each class.\nThe best value is 1, whereas the worst value is 0.\nIn the following steps, we employ different techniques to tackle the class imbalance. Our\nfirst approach is to utilize class weights to adjust our Decision Tree to an imbalanced\ndataset (step 3). The balanced mode uses the values of y to automatically adjust weights\ninversely proportional to the class frequencies in the input data as n_samples / (n_classes *\nnp.bincount(y)). In steps 4 to 7, we utilize upsampling to tackle class imbalance. This is the\nprocess of randomly duplicating observations from the minority class in order to reinforce\nthe minority class's signal.\nThere are several methods for doing so, but the most common way is to simply resample\nwith replacements as we have done. The two main concerns with upsampling are that it\nincreases the size of the dataset and that it can lead to overfitting due to training on the\nsame sample numerous times. In steps 8 to 10, we down-sample our major class. This\nsimply means that we don't use all of the samples we have, but just enough so that we\nbalance our classes.\nThe main issue with this technique is that we are forced to use a smaller training set. Our\nfinal approach, and the most sophisticated one, is to utilize a classifier that includes inner\nbalancing samplers, namely the BalancedBaggingClassifier from imbalanced-learn\n(step 11). Overall, we see that every single one of our methods for tackling class imbalance\nincreased the balanced accuracy score.","metadata":{"id":"yYnJ8Mmoi0nI"}}]}